
'use server';

/**
 * @fileOverview AI coach flow that integrates with the user's calendar data (mood, journal entries, tasks).
 *
 * - aiCoachCalendarIntegration - A function that orchestrates the AI coach interaction with calendar data to provide personalized suggestions.
 * - AICoachCalendarIntegrationInput - The input type for the aiCoachCalendarIntegration function.
 * - AICoachCalendarIntegrationOutput - The return type for the aiCoachCalendarIntegration function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

// Define a tool for adding tasks to the user's calendar
const addTaskTool = ai.defineTool(
    {
        name: 'addTask',
        description: 'Adds a list of tasks and wellness breaks to the user\'s calendar for the day. Use this when the user asks to plan something.',
        inputSchema: z.object({
            tasks: z.array(z.string()).describe("A list of task descriptions to be added."),
        }),
        outputSchema: z.object({ success: z.boolean() }),
    },
    async ({tasks}) => {
        // This is a client-side tool. The implementation is handled by the component
        // that calls the flow. Genkit uses this definition for prompting.
        // We just need to signal success back to the model.
        return { success: true };
    }
);

const AICoachCalendarIntegrationInputSchema = z.object({
  userId: z.string().describe('The ID of the user.'),
  userName: z.string().describe("The user's name."),
  preferredActivities: z.array(z.string()).optional().describe("A list of the user's preferred wellness activities."),
  calendarData: z.string().describe('The calendar data of the user including mood, journal entries, and tasks.'),
  query: z.string().describe('The user query or request to the AI coach.'),
  imageUri: z
    .string()
    .optional()
    .describe(
      "An optional image, as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:<mimetype>;base64,<encoded_data>'."
    ),
});
export type AICoachCalendarIntegrationInput = z.infer<typeof AICoachCalendarIntegrationInputSchema>;

const AICoachCalendarIntegrationOutputSchema = z.object({
  response: z.string().describe('The AI coach response to the user query, incorporating calendar data.'),
  suggestedTasks: z.array(z.string()).describe('A list of suggested tasks based on the calendar data.'),
  tasksToAdd: z.array(z.string()).optional().describe('A list of tasks to be added to the calendar, if any were generated by the addTask tool.')
});
export type AICoachCalendarIntegrationOutput = z.infer<typeof AICoachCalendarIntegrationOutputSchema>;

export async function aiCoachCalendarIntegration(input: AICoachCalendarIntegrationInput): Promise<AICoachCalendarIntegrationOutput> {
  return aiCoachCalendarIntegrationFlow(input);
}


const aiCoachCalendarIntegrationFlow = ai.defineFlow(
  {
    name: 'aiCoachCalendarIntegrationFlow',
    inputSchema: AICoachCalendarIntegrationInputSchema,
    outputSchema: AICoachCalendarIntegrationOutputSchema,
  },
  async (input) => {
    
    const activities = Array.isArray(input.preferredActivities) ? input.preferredActivities.join(', ') : 'not specified';

    // Construct the initial prompt with system instructions and user data.
    const promptMessage = {
        role: 'user' as const,
        content: [
            {
                type: 'text',
                text: `You are an AI emotional wellness coach in an app called Hugfeed. The user's name is ${input.userName}. Their preferred wellness activities are: ${activities}.

Your primary jobs are:
1.  **Be a conversational wellness partner**: If the user is just chatting, asking for advice, or sharing feelings, respond in a friendly, supportive, and insightful manner. Use their calendar data to provide context-aware guidance. You can suggest tasks they can add manually.
2.  **Be a task planner**: If the user explicitly asks you to plan something (e.g., "plan my afternoon", "add tasks for my project"), create a list of tasks for them.
    -   Break down large requests into smaller, specific tasks. (e.g., "work on my project" becomes "1. Research project topic", "2. Create outline").
    -   **CRUCIAL**: For every 2-3 tasks you create, you MUST add a short wellness break. Choose a break from the user's preferred activities. If none are specified, suggest a generic one like "Take a 5-minute stretch break" or "Practice mindful breathing for 2 minutes."
    -   Use the 'addTask' tool to send the list of generated tasks and breaks to the user's calendar.
3.  **Provide a summary response**: After using the tool (or if you don't need to), give a brief, friendly confirmation message to the user, like "I've added those tasks to your calendar for today!" or "Sounds like a plan! Let me know if you need anything else!".

Calendar Data (past 7 days):
${input.calendarData}

User Query:
"${input.query}"
`
            }
        ]
    };

    if (input.imageUri) {
        promptMessage.content.push({ type: 'media', data: { url: input.imageUri } });
        promptMessage.content.push({ type: 'text', text: 'The user has also uploaded an image. Analyze it in relation to the calendar data and user query to provide a more insightful response.' });
    }

    // First, send the prompt to the model to get its initial response, which may include tool calls.
    const llmResponse = await ai.generate({
      model: 'googleai/gemini-2.5-flash',
      tools: [addTaskTool],
      prompt: promptMessage,
    });

    const toolCalls = llmResponse.toolCalls();
    let generatedTasks: string[] = [];
    
    // Check if the model requested to use any tools.
    if (toolCalls.length > 0) {
        const toolResponses = [];
        for (const call of toolCalls) {
            // We only have one tool, but this pattern is good for multiple tools.
            if (call.tool === 'addTask') {
                // Store the tasks the AI wants to add.
                generatedTasks = call.input.tasks;
                // Create a response to send back to the model, confirming the tool "ran".
                toolResponses.push({
                    type: 'toolResponse',
                    ref: call.ref,
                    data: { output: { success: true } },
                });
            }
        }
        
        // If there were tool calls, we must send the tool responses back to the model
        // to get its final conversational text response.
        const finalResponse = await ai.generate({
            model: 'googleai/gemini-2.5-flash',
            prompt: [promptMessage, llmResponse.message, ...toolResponses],
        });

        return {
            response: finalResponse.text,
            suggestedTasks: [], // This can be populated in the future if needed.
            tasksToAdd: generatedTasks,
        };

    } else {
         // If no tools were called, the model's first response is the final one.
         return {
            response: llmResponse.text,
            suggestedTasks: [],
            tasksToAdd: [],
        };
    }
  }
);
